[
  {
    "round": 1,
    "metrics": {
      "method": "weighted_average",
      "num_ensembles": 2,
      "num_models": 7,
      "total_clients": 2,
      "authorized_clients": 2,
      "unauthorized_clients": 0,
      "avg_f1_score": 0.8333333333333333,
      "reward_distribution": {
        "current_rewards": {
          "0x79C62f4Ef6f1740D4C43A694Fe301abB7Ae97F28": {
            "total_score": 1081,
            "reward": 3.491320145337101,
            "contributions": 22,
            "previous_reward": 3.491320145337101
          },
          "0x888b72fA86F4277b632Bd03C54e2B7a5d524E031": {
            "total_score": 854,
            "reward": 2.75817521194994,
            "contributions": 23,
            "previous_reward": 2.75817521194994
          },
          "0x432eeDFD74F3CD992689f1cC2c0cB2758DdAB7fe": {
            "total_score": 260,
            "reward": 0.8397254743641501,
            "contributions": 8,
            "previous_reward": 0.8397254743641501
          },
          "0x9c4Ec6537bF4d916B71008003Fb1311B7C157C4f": {
            "total_score": 282,
            "reward": 0.9107791683488091,
            "contributions": 3,
            "previous_reward": 0.9107791683488091
          }
        },
        "historical_rewards": {
          "0x79C62f4Ef6f1740D4C43A694Fe301abB7Ae97F28": {
            "total_score": 1081,
            "total_reward": 6.9826402906742056,
            "contributions": 44
          },
          "0x888b72fA86F4277b632Bd03C54e2B7a5d524E031": {
            "total_score": 854,
            "total_reward": 5.516350423899878,
            "contributions": 46
          },
          "0x432eeDFD74F3CD992689f1cC2c0cB2758DdAB7fe": {
            "total_score": 260,
            "total_reward": 1.6794509487283003,
            "contributions": 16
          },
          "0x9c4Ec6537bF4d916B71008003Fb1311B7C157C4f": {
            "total_score": 282,
            "total_reward": 1.821558336697618,
            "contributions": 6
          }
        },
        "total_new_rewards": 8.0
      },
      "reward_avg_score": 44.232142857142854,
      "reward_score_range": 94,
      "reward_participants": 56,
      "avg_data_size": 8743.818181818182,
      "avg_training_rounds": 1.0,
      "avg_f1_evaluation": 0.7575757575757577
    },
    "num_clients": 2,
    "timestamp": "2025-05-19T19:03:35.191494+00:00"
  },
  {
    "round": 1,
    "eval_loss": 0.25,
    "eval_metrics": {
      "ensemble_accuracy": 0.9986301369863013,
      "diversity_score": 0.0030006523157208084,
      "true_positives": 3,
      "recall": 1.0,
      "true_negatives": 1454,
      "generalization_score": 0.49988558352402745,
      "convergence_rate": 1.0,
      "precision": 0.75,
      "ensemble_size": 7.0,
      "false_positives": 5,
      "f1_score": 0.8333333333333333,
      "loss": 0.25,
      "accuracy": 99.93160054719561,
      "false_negatives": 0,
      "num_clients": 2,
      "total_clients": 2,
      "authorized_clients": 2,
      "unauthorized_clients": 0,
      "avg_precision": 0.75,
      "avg_recall": 1.0,
      "avg_f1_score": 0.8333333333333333,
      "global_precision": 0.375,
      "global_recall": 1.0,
      "global_f1": 0.5454545454545454,
      "avg_accuracy": 99.93160054719561
    },
    "num_clients": 2,
    "timestamp": "2025-05-19T19:03:37.219515+00:00"
  },
  {
    "round": 2,
    "metrics": {
      "method": "weighted_average",
      "num_ensembles": 2,
      "num_models": 7,
      "total_clients": 2,
      "authorized_clients": 2,
      "unauthorized_clients": 0,
      "avg_f1_score": 0.8333333333333333,
      "reward_distribution": {
        "current_rewards": {
          "0x79C62f4Ef6f1740D4C43A694Fe301abB7Ae97F28": {
            "total_score": 678,
            "reward": 3.1246669907632483,
            "contributions": 15,
            "previous_reward": 3.1246669907632483
          },
          "0x888b72fA86F4277b632Bd03C54e2B7a5d524E031": {
            "total_score": 869,
            "reward": 4.0049197860962575,
            "contributions": 20,
            "previous_reward": 4.0049197860962575
          },
          "0x432eeDFD74F3CD992689f1cC2c0cB2758DdAB7fe": {
            "total_score": 253,
            "reward": 1.1659893048128342,
            "contributions": 7,
            "previous_reward": 1.1659893048128342
          },
          "0x9c4Ec6537bF4d916B71008003Fb1311B7C157C4f": {
            "total_score": 257,
            "reward": 1.1844239183276617,
            "contributions": 3,
            "previous_reward": 1.1844239183276617
          }
        },
        "historical_rewards": {
          "0x79C62f4Ef6f1740D4C43A694Fe301abB7Ae97F28": {
            "total_score": 678,
            "total_reward": 6.249333981526495,
            "contributions": 30
          },
          "0x888b72fA86F4277b632Bd03C54e2B7a5d524E031": {
            "total_score": 869,
            "total_reward": 8.009839572192512,
            "contributions": 40
          },
          "0x432eeDFD74F3CD992689f1cC2c0cB2758DdAB7fe": {
            "total_score": 253,
            "total_reward": 2.331978609625669,
            "contributions": 14
          },
          "0x9c4Ec6537bF4d916B71008003Fb1311B7C157C4f": {
            "total_score": 257,
            "total_reward": 2.3688478366553234,
            "contributions": 6
          }
        },
        "total_new_rewards": 9.480000000000002
      },
      "reward_avg_score": 45.71111111111111,
      "reward_score_range": 96,
      "reward_participants": 45,
      "avg_data_size": 8743.6,
      "avg_training_rounds": 2.0,
      "avg_f1_evaluation": 0.7666666666666667
    },
    "num_clients": 2,
    "timestamp": "2025-05-19T19:04:42.245568+00:00"
  },
  {
    "round": 2,
    "eval_loss": 0.25,
    "eval_metrics": {
      "ensemble_accuracy": 0.9986301369863013,
      "diversity_score": 0.0030006523157208084,
      "true_positives": 3,
      "recall": 1.0,
      "true_negatives": 1456,
      "generalization_score": 0.5,
      "convergence_rate": 1.0,
      "precision": 0.75,
      "ensemble_size": 7.0,
      "false_positives": 3,
      "f1_score": 0.8333333333333333,
      "loss": 0.25,
      "accuracy": 99.93160054719561,
      "false_negatives": 0,
      "num_clients": 2,
      "total_clients": 2,
      "authorized_clients": 2,
      "unauthorized_clients": 0,
      "avg_precision": 0.75,
      "avg_recall": 1.0,
      "avg_f1_score": 0.8333333333333333,
      "global_precision": 0.5,
      "global_recall": 1.0,
      "global_f1": 0.6666666666666666,
      "avg_accuracy": 99.93160054719561
    },
    "num_clients": 2,
    "timestamp": "2025-05-19T19:04:44.180232+00:00"
  },
  {
    "round": 3,
    "metrics": {
      "method": "weighted_average",
      "num_ensembles": 2,
      "num_models": 7,
      "total_clients": 2,
      "authorized_clients": 2,
      "unauthorized_clients": 0,
      "avg_f1_score": 0.8333333333333333,
      "reward_distribution": {
        "current_rewards": {
          "0x79C62f4Ef6f1740D4C43A694Fe301abB7Ae97F28": {
            "total_score": 679,
            "reward": 3.952494736842105,
            "contributions": 11,
            "previous_reward": 3.952494736842105
          },
          "0x888b72fA86F4277b632Bd03C54e2B7a5d524E031": {
            "total_score": 695,
            "reward": 4.0456315789473685,
            "contributions": 14,
            "previous_reward": 4.0456315789473685
          },
          "0x432eeDFD74F3CD992689f1cC2c0cB2758DdAB7fe": {
            "total_score": 232,
            "reward": 1.350484210526316,
            "contributions": 6,
            "previous_reward": 1.350484210526316
          },
          "0x9c4Ec6537bF4d916B71008003Fb1311B7C157C4f": {
            "total_score": 294,
            "reward": 1.7113894736842106,
            "contributions": 3,
            "previous_reward": 1.7113894736842106
          }
        },
        "historical_rewards": {
          "0x79C62f4Ef6f1740D4C43A694Fe301abB7Ae97F28": {
            "total_score": 679,
            "total_reward": 7.904989473684212,
            "contributions": 22
          },
          "0x888b72fA86F4277b632Bd03C54e2B7a5d524E031": {
            "total_score": 695,
            "total_reward": 8.091263157894739,
            "contributions": 28
          },
          "0x432eeDFD74F3CD992689f1cC2c0cB2758DdAB7fe": {
            "total_score": 232,
            "total_reward": 2.700968421052632,
            "contributions": 12
          },
          "0x9c4Ec6537bF4d916B71008003Fb1311B7C157C4f": {
            "total_score": 294,
            "total_reward": 3.4227789473684216,
            "contributions": 6
          }
        },
        "total_new_rewards": 11.06
      },
      "reward_avg_score": 55.88235294117647,
      "reward_score_range": 98,
      "reward_participants": 34,
      "avg_data_size": 8743.333333333334,
      "avg_training_rounds": 3.0,
      "avg_f1_evaluation": 0.7777777777777778
    },
    "num_clients": 2,
    "timestamp": "2025-05-19T19:05:50.711910+00:00"
  },
  {
    "round": 3,
    "eval_loss": 0.25,
    "eval_metrics": {
      "ensemble_accuracy": 0.9986301369863013,
      "diversity_score": 0.0030006523157208084,
      "true_positives": 3,
      "recall": 1.0,
      "true_negatives": 1456,
      "generalization_score": 0.5,
      "convergence_rate": 1.0,
      "precision": 0.75,
      "ensemble_size": 7.0,
      "false_positives": 3,
      "f1_score": 0.8333333333333333,
      "loss": 0.25,
      "accuracy": 99.93160054719561,
      "false_negatives": 0,
      "num_clients": 2,
      "total_clients": 2,
      "authorized_clients": 2,
      "unauthorized_clients": 0,
      "avg_precision": 0.75,
      "avg_recall": 1.0,
      "avg_f1_score": 0.8333333333333333,
      "global_precision": 0.5,
      "global_recall": 1.0,
      "global_f1": 0.6666666666666666,
      "avg_accuracy": 99.93160054719561
    },
    "num_clients": 2,
    "timestamp": "2025-05-19T19:05:52.295779+00:00"
  }
]